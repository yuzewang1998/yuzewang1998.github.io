<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane</title>

    <meta name="description"
        content="GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--FACEBOOK-->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://GOI-Hyperplane.github.io" />
    <meta property="og:title" content="GOI: Find 3D Gaussians of Interest" />
    <meta property="og:description"
        content="GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane" />

    <!--TWITTER-->
    <meta name="twitter:url" content="https://GOI-Hyperplane.github.io" />
    <meta name="twitter:card" content="summary_large_image" />

    <link rel="icon" href="paint.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="assets/css/bog/app.css">

    <link rel="stylesheet" href="assets/css/bog/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>

    <link rel="stylesheet" href="assets/css/bog/dics.min.css">
    <script src="assets/js/bog/dics.min.js"></script>
    <script src="assets/js/bog/video_comparison.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>GOI</b>: Find 3D <span style="font-weight: 500">G</span>aussians <span style="font-weight: 500">o</span>f <span style="font-weight: 500">I</span>nterest with an Optimizable </br> Open-vocabulary Semantic-space Hyperplane </br>
            </h2>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="">Yansong Qu<sup>*</sup></a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Shaohui Dai<sup>*</sup></a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Xinyang Li</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Jianghang Lin</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Liujuan Cao<sup>†</sup></a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Shengchuan Zhang</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>
                    <li>
                        <a href="">Rongrong Ji</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
                    </li>                    
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                Key Laboratory of Multimedia Trusted Perception and Efficient Computing, <br>
                Ministry of Education of China, Xiamen University, Fujian, China
            </h5>
        </div>


        <div class="row">
            <div class="publication-links">
                <div class=link-block>
                    <a href="https://arxiv.org/pdf/2405.17596" class="external-link button is-normal is-rounded is-dark">
                    <span class=icon>
                    <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden=true focusable=false data-prefix=fas data-icon=file-pdf role=img xmlns=http://www.w3.org/2000/svg viewBox="0 0 384 512" data-fa-i2svg><path fill=currentColor d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
                    </span>
                    <span>Paper</span>
                    </a>
                </div>
                <div class=link-block>
                    <a href="https://arxiv.org/abs/2405.17596" class="external-link button is-normal is-rounded is-dark">
                    <span class=icon>
                    <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                </div>
                <div class=link-block>
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class=icon>
                    <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden=true focusable=false data-prefix=fab data-icon=github role=img xmlns=http://www.w3.org/2000/svg viewBox="0 0 496 512" data-fa-i2svg><path fill=currentColor d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
                    </span>
                    <span>Code (Coming soon)</span>
                    </a>
                </div>
                <div class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <svg class="svg-inline--fa fa-images fa-w-18" aria-hidden="true" focusable="false" data-prefix="far" data-icon="images" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M480 416v16c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V176c0-26.51 21.49-48 48-48h16v48H54a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6v-10h48zm42-336H150a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6V86a6 6 0 0 0-6-6zm6-48c26.51 0 48 21.49 48 48v256c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V80c0-26.51 21.49-48 48-48h384zM264 144c0 22.091-17.909 40-40 40s-40-17.909-40-40 17.909-40 40-40 40 17.909 40 40zm-72 96l39.515-39.515c4.686-4.686 12.284-4.686 16.971 0L288 240l103.515-103.515c4.686-4.686 12.284-4.686 16.971 0L480 208v80H192v-48z"></path></svg><!-- <i class="far fa-images"></i> Font Awesome fontawesome.com -->
                        </span>
                        <span>Data (Coming soon)</span>
                        </a>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video class="video" width="100%" id="teaser" loop playsinline autoplay muted src="video/teaser.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
                <canvas height=0 class="videoMerge" id="teaserMerge"></canvas>
			</div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-center">
                    Semantic segmentation result of GOI. The left video shows the rendered 3D scene, and the right video shows the semantic segmentation result.
                    <br /> 
                </p>
			</div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    TL;DR
                </h3>
                
                <div class="banner">
                    GOI can locate 3D gaussians of interests as directed by open-vocabulary prompts.
                </div>

                <br />
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    3D open-vocabulary scene understanding, crucial for advancing augmented reality and robotic applications, 
                    involves interpreting and locating specific regions within a 3D space as directed by natural language instructions. 
                    To this end, we introduce GOI, a framework that integrates semantic features from 2D vision-language foundation models into 
                    3D Gaussian Splatting (3DGS) and identifies 3D Gaussians of Interest using an Optimizable Semantic-space Hyperplane. 
                    Our approach includes an efficient compression method that utilizes scene priors to condense noisy high-dimensional semantic features 
                    into compact low-dimensional vectors, which are subsequently embedded in 3DGS. 
                    During the open-vocabulary querying process, we adopt a distinct approach compared to existing methods, 
                    which depend on a manually set fixed empirical threshold to select regions based on their semantic feature distance to the query text embedding. 
                    This traditional approach often lacks universal accuracy, leading to challenges in precisely identifying specific target areas. 
                    Instead, our method treats the feature selection process as a hyperplane division within the feature space, 
                    retaining only those features that are highly relevant to the query. 
                    We leverage off-the-shelf 2D Referring Expression Segmentation (RES) models to fine-tune the semantic-space hyperplane, 
                    enabling a more precise distinction between target regions and others. This fine-tuning substantially improves the accuracy of open-vocabulary queries, 
                    ensuring the precise localization of pertinent 3D Gaussians. Extensive experiments demonstrate GOI's superiority over previous state-of-the-art methods. 
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                <div class="text-center">
                    <img src="image/pipeline.png" width="100%">
                </div>
                <div class="text-justify">
                    <p>
                        The framework of our GOI. <b>Top left</b>: Reconstruction of a 3D Gaussian scene, encoding multi-view images. 
                        <b>Bottom left</b>: The optimization process. For each training view, a low-dimensional (LD) feature map is rendered through Gaussian Rasterizer 
                        and transformed into a predicted feature map via the Trainable Feature Clustering Codebook (TFCC). 
                        <b>Right</b>: The pipeline illustrates open-vocabulary querying. 
                        The processes denoted by <img src="image/mathcal_r.png" width="14px"> and <img src="image/mathcal_f.png" width="14px"> 
                        correspond to rendering and feature map prediction, respectively. 
                        The red line indicates operations exclusive to the initial query with a new text prompt. 
                        During these operations, the Optimizable Semantic-space Hyperplane (OSH) is fine-tuned to more precisely delineate the target region.
                    </p>
            </div>
        </div>




        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video Comparison
                </h3>
                <p>Below shows a comparison between our work and other recent language embedded NeRF or 3DGS scenes.</p>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <div class="div-comp-video">
                    <video class="responsive-video" controls autoplay loop muted>
                        <source src="./video/room.mp4" type="video/mp4" />
                    </video>
                </div>
                <div class="text-center">
                    <p> prompt: <i>"sofa in dark green"</i> </p>
                </div>
            </div>
            <br />

            <div class="col-md-8 col-md-offset-2">
                <div class="div-comp-video">
                    <video class="responsive-video" controls autoplay loop muted>
                        <source src="./video/bonsai.mp4" type="video/mp4" />
                    </video>
                </div>
                <div class="text-center">
                    <p> prompt: <i>"flowerpot on the table"</i> </p>
                </div>
            </div>

            <div class="col-md-8 col-md-offset-2">
                <div class="div-comp-video">
                    <video class="responsive-video" controls autoplay loop muted>
                        <source src="./video/garden.mp4" type="video/mp4" />
                    </video>
                </div>
                <div class="text-center">
                    <p> prompt: <i>"green grass"</i> </p>
                </div>
            </div>

            <div class="col-md-8 col-md-offset-2">
                <div class="div-comp-video">
                    <video class="responsive-video" controls autoplay loop muted>
                        <source src="./video/kitchen.mp4" type="video/mp4" />
                    </video>
                </div>
                <div class="text-center">
                    <p> prompt: <i>"the tablemat next to the red gloves"</i> </p>
                </div>
            </div>


            <div class="col-md-8 col-md-offset-2">
                <h4>
                    More Results
                </h4>

            </div>
            <div class="col-md-8 col-md-offset-2">
                <div style="text-align: center;"><b>Mip-NeRF 360 dataset</b></div>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-table.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"table under the bowl"</i> </p>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-lego.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"Lego bulldozer"</i> </p>
                            </div>
                        </td>
                    </tr>
                </table>
                <div style="text-align: center;"><b>LERF dataset</b></div>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-teatime.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"cookies"</i> </p>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-figurines.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"red apple"</i> </p>
                            </div>
                        </td>
                    </tr>
                </table>
                <div style="text-align: center;"><b>Replica dataset</b></div>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-replica0.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"stool"</i> </p>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline autoplay loop muted>
                                <source src="video/comp-replica1.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"pillow"</i> </p>
                            </div>
                        </td>
                    </tr>
                </table>
                <div style="text-align: center;"><b>ScanNet dataset</b></div>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline autoplay loop muted>
                                <source src="video/sn-chair.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"chair"</i> </p>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline autoplay loop muted>
                                <source src="video/sn-shelf.mp4" type="video/mp4" />
                            </video>
                            <div class="text-center" style="font-size: 14px;">
                                <p> prompt: <i>"the shelf under a toy"</i> </p>
                            </div>
                        </td>
                    </tr>
                </table>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Scene Editing
                </h3>
                <p>
                    Our method can be applied to a variety of downstream tasks, 
                    with the most direct application being the editing of 3D scenes.
                </p>
                <div class="text-center">
                    <img src="image/edit.png" width="100%">
                </div>
                <div class="text-center">
                    <p> prompt: <i>"flowerpot on the table"</i> </p>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <p>
                    If you want to cite our work, please use:
                </p>
<pre style="font-size: 12px;">
@article{goi2024,
    title={GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane},
    author={Qu, Yansong and Dai, Shaohui and Li, Xinyang and Lin, Jianghang and Cao, Liujuan and Zhang, Shengchuan and Ji, Rongrong},
    journal={arXiv preprint arXiv:2405.17596},
    year={2024}
}
</pre>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    The website template was borrowed from <a href="http://mgharbi.com/">Michaël
                        Gharbi</a> and <a href="https://jonbarron.info/mipnerf360/">MipNeRF360</a>.
                </p>
            </div>
        </div>

    </div>
</body>

</html>